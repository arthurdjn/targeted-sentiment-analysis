{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"bert.ipynb","provenance":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"RCZFBpOD8FR4","colab_type":"text"},"source":["# **BERT for Targeted Sentiment Analysis**"]},{"cell_type":"markdown","metadata":{"id":"Y6IA8yll8FR9","colab_type":"text"},"source":["# 1. Load the data"]},{"cell_type":"code","metadata":{"id":"DKMBuGOR8ZCB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":391},"outputId":"3b4dcd37-1852-4235-def1-fd4fcd1e4ee7","executionInfo":{"status":"ok","timestamp":1589057441604,"user_tz":-120,"elapsed":8145,"user":{"displayName":"A Amberson","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMv-zo4U89Ukg9VN1qA2GXdtO-fFJ8jUUarC0cGA=s64","userId":"03713416321102018803"}}},"source":["!pip install pytorch_pretrained_bert"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting pytorch_pretrained_bert\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n","\r\u001b[K     |██▋                             | 10kB 26.4MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20kB 29.5MB/s eta 0:00:01\r\u001b[K     |████████                        | 30kB 34.4MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 40kB 38.0MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 51kB 31.7MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61kB 34.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 71kB 28.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 81kB 30.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 92kB 31.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 102kB 29.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 112kB 29.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 122kB 29.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 29.7MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.18.4)\n","Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2019.12.20)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.13.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (4.41.1)\n","Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.5.0+cu101)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2.23.0)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.9.5)\n","Requirement already satisfied: botocore<1.17.0,>=1.16.3 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (1.16.3)\n","Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.3.3)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (0.16.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2.9)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2020.4.5.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.3->boto3->pytorch_pretrained_bert) (2.8.1)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.3->boto3->pytorch_pretrained_bert) (0.15.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.17.0,>=1.16.3->boto3->pytorch_pretrained_bert) (1.12.0)\n","Installing collected packages: pytorch-pretrained-bert\n","Successfully installed pytorch-pretrained-bert-0.6.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","id":"8Ua9J_5x8FSB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"842ed5ac-7008-4b30-c976-6c0b21a1e6e9","executionInfo":{"status":"ok","timestamp":1589057447468,"user_tz":-120,"elapsed":13942,"user":{"displayName":"A Amberson","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMv-zo4U89Ukg9VN1qA2GXdtO-fFJ8jUUarC0cGA=s64","userId":"03713416321102018803"}}},"source":["import numpy as np\n","import pandas as pd\n","\n","import torch\n","from torch.optim import Adam\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","import torchtext\n","from torchtext.vocab import Vectors\n","from torchtext.datasets import SequenceTaggingDataset\n","\n","from keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","from pytorch_pretrained_bert import BertTokenizer, BertConfig\n","from pytorch_pretrained_bert import BertForTokenClassification, BertAdam"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"ij7aF1OY8LFl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"outputId":"011bffd2-6a3c-4fad-be09-44ce73069161","executionInfo":{"status":"ok","timestamp":1589057740713,"user_tz":-120,"elapsed":307125,"user":{"displayName":"A Amberson","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMv-zo4U89Ukg9VN1qA2GXdtO-fFJ8jUUarC0cGA=s64","userId":"03713416321102018803"}}},"source":["from google.colab import drive\n","drive.mount(\"data\")"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","id":"pFOiPQZf8FSZ","colab_type":"code","colab":{}},"source":["class NoReCfine(SequenceTaggingDataset):\n","    def __init__(self, path, fields, encoding=\"utf-8\", separator=\"\\t\", **kwargs):\n","        super().__init__(path, fields)\n","\n","    @classmethod\n","    def splits(cls, fields, train_data=\"data/My Drive/projects/deep_learning/in5550-exam/data/train.conll\", dev_data=\"data/My Drive/projects/deep_learning/in5550-exam/data/dev.conll\", test_data=\"data/My Drive/projects/deep_learning/in5550-exam/data/test.conll\"):\n","        return NoReCfine(train_data, fields), NoReCfine(dev_data, fields), NoReCfine(test_data, fields)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"_uuid":"fa91210f9bc73bfa267e2420780f492d83be7af1","scrolled":true,"id":"K3rPUizN8FSx","colab_type":"code","colab":{}},"source":["TEXT = torchtext.data.Field(lower=False, include_lengths=True, batch_first=True, pad_token=None)\n","LABEL = torchtext.data.Field(batch_first=True, unk_token=None, pad_token=None)\n","FIELDS = [(\"text\", TEXT), (\"label\", LABEL)]\n","\n","train_data, valid_data, test_data = NoReCfine.splits(FIELDS)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"_uuid":"ef6bcf215604b4247864be63c03e9032f6f558e2","id":"j5ASiPIH8FTA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":119},"outputId":"78b6fc27-ba73-4442-a8a5-c9f019faff7f","executionInfo":{"status":"ok","timestamp":1589057746741,"user_tz":-120,"elapsed":313049,"user":{"displayName":"A Amberson","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMv-zo4U89Ukg9VN1qA2GXdtO-fFJ8jUUarC0cGA=s64","userId":"03713416321102018803"}}},"source":["print(f'Number of training examples: {len(train_data):,}')\n","print(f'Number of training examples: {len(valid_data):,}')\n","print(f'Number of testing examples:    {len(test_data)}')\n","\n","text_length = [len(sentence) for sentence in list(train_data.text)]\n","\n","print(f\"\\nNumber of sentences in train_data.text: {len(text_length)}\")\n","print(f'Number of words in train_data: {sum(text_length):,}')"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Number of training examples: 5,915\n","Number of training examples: 1,151\n","Number of testing examples:    895\n","\n","Number of sentences in train_data.text: 5915\n","Number of words in train_data: 98,483\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_KPGpSJu8FTT","colab_type":"code","colab":{}},"source":["# Create the vocabulary for words embeddings\n","LABEL.build_vocab(train_data)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"_uuid":"9a58a0ecf1eb30dcc554a87ab819505dec6d99ef","id":"Em0SdSJB8FTh","colab_type":"code","colab":{}},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","n_gpu = torch.cuda.device_count()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"_uuid":"c5dd0ef060e6d26d1ab695725bbe7a26c8c6f4c1","id":"nFG0wgri8FTw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"90eafc00-b874-46a8-8a6f-1f02b9569774","executionInfo":{"status":"ok","timestamp":1589057746748,"user_tz":-120,"elapsed":312468,"user":{"displayName":"A Amberson","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMv-zo4U89Ukg9VN1qA2GXdtO-fFJ8jUUarC0cGA=s64","userId":"03713416321102018803"}}},"source":["torch.cuda.get_device_name(0) "],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Tesla P4'"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"_uuid":"dc6cd04bb8e9ba1d4bf398ee9fc3af97ad7d0fc3","id":"3IOeMw0l8FUC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"8f674182-9431-408b-bf5e-22da546ecb2d","executionInfo":{"status":"ok","timestamp":1589057749220,"user_tz":-120,"elapsed":314885,"user":{"displayName":"A Amberson","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMv-zo4U89Ukg9VN1qA2GXdtO-fFJ8jUUarC0cGA=s64","userId":"03713416321102018803"}}},"source":["tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["100%|██████████| 995526/995526 [00:01<00:00, 900849.38B/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"xGc9OFbS8FUP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"6afbb5ae-405e-412b-a683-97f01507125a","executionInfo":{"status":"ok","timestamp":1589057749225,"user_tz":-120,"elapsed":314863,"user":{"displayName":"A Amberson","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMv-zo4U89Ukg9VN1qA2GXdtO-fFJ8jUUarC0cGA=s64","userId":"03713416321102018803"}}},"source":["train_sentences = [' '.join(sentence.text) for sentence in train_data]\n","valid_sentences = [' '.join(sentence.text) for sentence in valid_data]\n","\n","train_sentences[25]"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Ja , jeg snakker til deg , Deep Blue .'"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"lzqk9DDl8FUe","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"outputId":"abd273bf-0f9f-472c-8e1d-ddcca50e242f","executionInfo":{"status":"ok","timestamp":1589057750383,"user_tz":-120,"elapsed":315994,"user":{"displayName":"A Amberson","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMv-zo4U89Ukg9VN1qA2GXdtO-fFJ8jUUarC0cGA=s64","userId":"03713416321102018803"}}},"source":["max_seq_len = np.max([len(sentence.text) for sentence in train_data])\n","tags2vals = {i: lab for i, lab in enumerate(LABEL.vocab.itos)}\n","tag2idx = {lab: i for i, lab in enumerate(LABEL.vocab.itos)}\n","\n","print(f\"max: {max_seq_len}\")\n","print(f\"labels: {LABEL.vocab.itos}\")\n","print(f\"tag2idx: {tag2idx}\")"],"execution_count":12,"outputs":[{"output_type":"stream","text":["max: 103\n","labels: ['O', 'I-targ-Positive', 'B-targ-Positive', 'I-targ-Negative', 'B-targ-Negative']\n","tag2idx: {'O': 0, 'I-targ-Positive': 1, 'B-targ-Positive': 2, 'I-targ-Negative': 3, 'B-targ-Negative': 4}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Itoh-j-_8FUz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"7c7111b6-ba14-478f-85f7-7f80625f192a","executionInfo":{"status":"ok","timestamp":1589057750868,"user_tz":-120,"elapsed":316452,"user":{"displayName":"A Amberson","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMv-zo4U89Ukg9VN1qA2GXdtO-fFJ8jUUarC0cGA=s64","userId":"03713416321102018803"}}},"source":["train_tokenized = [tokenizer.tokenize(sent) for sent in train_sentences]\n","train_labels = [sentence.label for sentence in train_data]\n","\n","valid_tokenized = [tokenizer.tokenize(sent) for sent in valid_sentences]\n","valid_labels = [sentence.label for sentence in valid_data]\n","\n","print(train_tokenized[2])\n","print(train_labels[2])"],"execution_count":13,"outputs":[{"output_type":"stream","text":["['Tin', '##ie', 'Tem', '##pah', 'sk', '##uff', '##er', '.']\n","['B-targ-Negative', 'I-targ-Negative', 'O', 'O']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"_uuid":"56456d4978d04fac19ffbb0d22a613a0734e4c1c","id":"RHcvzWC58FVE","colab_type":"code","colab":{}},"source":["X_train = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in train_tokenized],\n","                   maxlen=max_seq_len, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","\n","X_valid = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in train_tokenized],\n","                   maxlen=max_seq_len, dtype=\"long\", truncating=\"post\", padding=\"post\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"_uuid":"d42470c504501848fa88fb829f97ce162d80ef6c","id":"DTRO_fxJ8FVU","colab_type":"code","colab":{}},"source":["Y_train = pad_sequences([[tag2idx.get(l) for l in lab] for lab in train_labels],\n","                     maxlen=max_seq_len, value=tag2idx[\"O\"], padding=\"post\",\n","                     dtype=\"long\", truncating=\"post\")\n","\n","Y_valid = pad_sequences([[tag2idx.get(l) for l in lab] for lab in train_labels],\n","                     maxlen=max_seq_len, value=tag2idx[\"O\"], padding=\"post\",\n","                     dtype=\"long\", truncating=\"post\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"_uuid":"41f57a758891a4d9ed7eb444c03583f88aa786ba","id":"KXqAcSSa8FVh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"bdd202eb-7280-4bbd-baa8-9e1b7e0da711","executionInfo":{"status":"ok","timestamp":1589057751329,"user_tz":-120,"elapsed":316790,"user":{"displayName":"A Amberson","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMv-zo4U89Ukg9VN1qA2GXdtO-fFJ8jUUarC0cGA=s64","userId":"03713416321102018803"}}},"source":["X_train.shape # (sentences, maximum sequence length)"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(5915, 103)"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"_uuid":"9f7af71fe6b7bbe9ce804fcf1dd4472ca5366fbe","id":"ZPs8ii7g8FVw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"9c0ff5a0-ee13-4fd3-8994-8f70703a9bba","executionInfo":{"status":"ok","timestamp":1589057751331,"user_tz":-120,"elapsed":316758,"user":{"displayName":"A Amberson","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMv-zo4U89Ukg9VN1qA2GXdtO-fFJ8jUUarC0cGA=s64","userId":"03713416321102018803"}}},"source":["Y_train.shape"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(5915, 103)"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"_uuid":"2902f1b07bca78a0b34698ef64b1f35eabf50b2f","id":"7N2SzbJ08FV_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":136},"outputId":"71cd737e-8f1b-4f44-b08f-887f992e5218","executionInfo":{"status":"ok","timestamp":1589057751334,"user_tz":-120,"elapsed":316732,"user":{"displayName":"A Amberson","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMv-zo4U89Ukg9VN1qA2GXdtO-fFJ8jUUarC0cGA=s64","userId":"03713416321102018803"}}},"source":["X_train"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 13258,  10216,  85202, ...,      0,      0,      0],\n","       [ 11771,  12457,  14946, ...,      0,      0,      0],\n","       [ 48800,  10400,  53696, ...,      0,      0,      0],\n","       ...,\n","       [ 15651, 109275,  38424, ...,      0,      0,      0],\n","       [ 66717,  10217,  14547, ...,      0,      0,      0],\n","       [ 10666,  10163,  32472, ...,      0,      0,      0]])"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"_uuid":"537fb21b3637534a653aec22b8be933ffb03207c","id":"GVI0xRaq8FWQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":136},"outputId":"f0eda7a8-454a-46c7-b44d-db2c4e3f1896","executionInfo":{"status":"ok","timestamp":1589057751338,"user_tz":-120,"elapsed":316707,"user":{"displayName":"A Amberson","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMv-zo4U89Ukg9VN1qA2GXdtO-fFJ8jUUarC0cGA=s64","userId":"03713416321102018803"}}},"source":["Y_train"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0, 0, 4, ..., 0, 0, 0],\n","       [2, 1, 1, ..., 0, 0, 0],\n","       [4, 3, 0, ..., 0, 0, 0],\n","       ...,\n","       [0, 0, 0, ..., 0, 0, 0],\n","       [0, 0, 0, ..., 0, 0, 0],\n","       [0, 0, 0, ..., 0, 0, 0]])"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"_uuid":"4a5204c0bd9f595f24f59c69dba950c3774e359a","id":"rYcNZWWC8FWx","colab_type":"code","colab":{}},"source":["attention_masks_train = [[float(i>0) for i in ii] for ii in X_train]\n","attention_masks_valid = [[float(i>0) for i in ii] for ii in X_valid]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"_uuid":"13abf578090d6191fcf32e6e970ed15e4d17595a","id":"LUCAO9o68FW-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"cb4949d5-3a52-49ce-f2fd-e257c9ff8568","executionInfo":{"status":"ok","timestamp":1589057752531,"user_tz":-120,"elapsed":317842,"user":{"displayName":"A Amberson","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMv-zo4U89Ukg9VN1qA2GXdtO-fFJ8jUUarC0cGA=s64","userId":"03713416321102018803"}}},"source":["len(attention_masks_train) # list of lists of shape (sentences, labels )"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["5915"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"_uuid":"64bdffc7ba465fb18a0c46b11daba59b7f86a183","id":"w1IRy13t8FXK","colab_type":"code","colab":{}},"source":["# X_train, X_valid, Y_train, Y_valid = train_test_split(X, Y, \n","#                                                             random_state=20, test_size=0.1)\n","# Mask_train, Mask_valid, _, _ = train_test_split(attention_masks, X,\n","#                                              random_state=20, test_size=0.1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"_uuid":"3e0d6c5224658787d50addfd5d40bbc602914ee2","id":"BfSDyczA8FXX","colab_type":"code","colab":{}},"source":["X_train = torch.tensor(X_train)\n","X_valid = torch.tensor(X_valid)\n","Y_train = torch.tensor(Y_train)\n","Y_valid = torch.tensor(Y_valid)\n","Mask_train = torch.tensor(attention_masks_train)\n","Mask_valid = torch.tensor(attention_masks_valid)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"_uuid":"d786b080f7c6f705c8dcd50a7ee6d9acf893b38b","id":"88quTt-s8FXk","colab_type":"code","colab":{}},"source":["batch_s = 32\n","\n","data_train = TensorDataset(X_train, Mask_train, Y_train)\n","data_train_sampler = RandomSampler(data_train)\n","DL_train = DataLoader(data_train, sampler=data_train_sampler, batch_size=batch_s)\n","\n","data_valid = TensorDataset(X_valid, Mask_valid, Y_valid)\n","data_valid_sampler = SequentialSampler(data_valid)\n","DL_valid = DataLoader(data_valid, sampler=data_valid_sampler, batch_size=batch_s)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"_uuid":"1b7700ca59220d0e07647ee95ae49259fbb77c1a","id":"QBTwdx_g8FXw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"f95ceafe-f94c-46ed-b53f-bb3cc5461973","executionInfo":{"status":"ok","timestamp":1589057836924,"user_tz":-120,"elapsed":402126,"user":{"displayName":"A Amberson","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMv-zo4U89Ukg9VN1qA2GXdtO-fFJ8jUUarC0cGA=s64","userId":"03713416321102018803"}}},"source":["model = BertForTokenClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=len(tag2idx))"],"execution_count":25,"outputs":[{"output_type":"stream","text":["100%|██████████| 662804195/662804195 [01:08<00:00, 9727419.95B/s] \n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"_uuid":"08f77d24bff1417c049fbfe38cb29dc0fbfe2b71","id":"QkmZuVFe8FX7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"9cd1328a-ad44-4df9-92a4-418823c7fa77","executionInfo":{"status":"ok","timestamp":1589057852912,"user_tz":-120,"elapsed":418081,"user":{"displayName":"A Amberson","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMv-zo4U89Ukg9VN1qA2GXdtO-fFJ8jUUarC0cGA=s64","userId":"03713416321102018803"}}},"source":["model.cuda()\n","print('model on cuda')"],"execution_count":26,"outputs":[{"output_type":"stream","text":["model on cuda\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"_uuid":"f709552931616bc829dba371fb172d1d9d761092","id":"lwebQApk8FYG","colab_type":"code","colab":{}},"source":["FULL_FINETUNING = True\n","\n","if FULL_FINETUNING:\n","    param_optimizer = list(model.named_parameters())\n","    no_decay = ['bias', 'gamma', 'beta']\n","    optimizer_grouped_parameters = [\n","        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n","         'weight_decay_rate': 0.01},\n","        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n","         'weight_decay_rate': 0.0}\n","    ]\n","else:\n","    param_optimizer = list(model.classifier.named_parameters()) \n","    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n","optimizer = Adam(optimizer_grouped_parameters, lr=3e-5)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"F54CWRcU9oJ0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":306},"outputId":"878b8381-80d5-47b6-ea5b-3f872f180563","executionInfo":{"status":"ok","timestamp":1589057858868,"user_tz":-120,"elapsed":423981,"user":{"displayName":"A Amberson","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMv-zo4U89Ukg9VN1qA2GXdtO-fFJ8jUUarC0cGA=s64","userId":"03713416321102018803"}}},"source":["!pip install seqeval"],"execution_count":28,"outputs":[{"output_type":"stream","text":["Collecting seqeval\n","  Downloading https://files.pythonhosted.org/packages/34/91/068aca8d60ce56dd9ba4506850e876aba5e66a6f2f29aa223224b50df0de/seqeval-0.0.12.tar.gz\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from seqeval) (1.18.4)\n","Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.6/dist-packages (from seqeval) (2.3.1)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (2.10.0)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.4.1)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.0.8)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (3.13)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.1.0)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.12.0)\n","Building wheels for collected packages: seqeval\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-0.0.12-cp36-none-any.whl size=7424 sha256=d9b5456a4a409e4376709348e85e727bad16048b40baa2ee78ec624ad7654927\n","  Stored in directory: /root/.cache/pip/wheels/4f/32/0a/df3b340a82583566975377d65e724895b3fad101a3fb729f68\n","Successfully built seqeval\n","Installing collected packages: seqeval\n","Successfully installed seqeval-0.0.12\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"_uuid":"3011c3b0a523596d9541f59c5135383b6313f70f","id":"9ILLffct8FYY","colab_type":"code","colab":{}},"source":["from seqeval.metrics import f1_score\n","\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=2).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"_uuid":"896a9673560344c4d5d26deeceae545902ebac19","id":"_BrcxuFi8FYl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":904},"outputId":"edea05bc-7219-486a-8298-5fdb1e659f88","executionInfo":{"status":"error","timestamp":1589057862022,"user_tz":-120,"elapsed":427056,"user":{"displayName":"A Amberson","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMv-zo4U89Ukg9VN1qA2GXdtO-fFJ8jUUarC0cGA=s64","userId":"03713416321102018803"}}},"source":["epochs = 5\n","max_grad_norm = 1.0\n","\n","for epoch in range(epochs):\n","    # TRAIN loop\n","    print(f\"Epoch: {epoch}\")\n","    model.train()\n","    tr_loss = 0\n","    nb_tr_examples, nb_tr_steps = 0, 0\n","    for step, batch in enumerate(DL_train):\n","        # add batch to gpu\n","#         batch = tuple(t.to(device) for t in batch)\n","        b_input_ids, b_input_mask, b_labels = batch\n","        b_input_ids, b_input_mask, b_labels = b_input_ids.to(device), b_input_mask.to(device), b_labels.to(device)\n","        # forward pass\n","        loss = model(b_input_ids.long(), token_type_ids=None,\n","                     attention_mask=b_input_mask.long(), labels=b_labels.long())\n","        # backward pass\n","        loss.backward()\n","        # track train loss\n","        tr_loss += loss.item()\n","        nb_tr_examples += b_input_ids.size(0)\n","        nb_tr_steps += 1\n","        # gradient clipping\n","        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n","        # update parameters\n","        optimizer.step()\n","        model.zero_grad()\n","        print(f\"\\rStep:{step+1:5d}/{len(DL_train)}\", end='')\n","    # print train loss per epoch\n","    print(\"\\nTrain loss: {}\".format(tr_loss/nb_tr_steps))\n","    # VALIDATION on validation set\n","    model.eval()\n","    eval_loss, eval_accuracy = 0, 0\n","    nb_eval_steps, nb_eval_examples = 0, 0\n","    predictions , true_labels = [], []\n","    for step, batch in enumerate(DL_valid):\n","        batch = tuple(t.to(device) for t in batch)\n","        b_input_ids, b_input_mask, b_labels = batch\n","        \n","        with torch.no_grad():\n","            tmp_eval_loss = model(b_input_ids.long(), token_type_ids=None,\n","                                  attention_mask=b_input_mask, labels=b_labels)\n","            logits = model(b_input_ids, token_type_ids=None,\n","                           attention_mask=b_input_mask)\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","        predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n","        true_labels.append(label_ids)\n","        \n","        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n","        \n","        eval_loss += tmp_eval_loss.mean().item()\n","        eval_accuracy += tmp_eval_accuracy\n","        \n","        nb_eval_examples += b_input_ids.size(0)\n","        nb_eval_steps += 1\n","        print(f\"\\rStep:{step+1:5d}/{len(DL_valid)}\", end='')\n","    eval_loss = eval_loss/nb_eval_steps\n","    print(\"\\nValidation loss: {}\".format(eval_loss))\n","    print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n","    pred_tags = [tags2vals[p_i] for p in predictions for p_i in p]\n","    valid_tags = [tags2vals[l_ii] for l in true_labels for l_i in l for l_ii in l_i]\n","    print(\"F1-Score: {}\".format(f1_score(pred_tags, valid_tags)))\n","    print(\"--------------------------------------------------\\n\")"],"execution_count":30,"outputs":[{"output_type":"stream","text":["Epoch: 0\n","Step:    1/185"],"name":"stdout"},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-b2365ae1ba5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m                      attention_mask=b_input_mask.long(), labels=b_labels.long())\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;31m# track train loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 40.00 MiB (GPU 0; 7.43 GiB total capacity; 6.60 GiB already allocated; 2.94 MiB free; 6.83 GiB reserved in total by PyTorch) (malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:289)\nframe #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x46 (0x7f65a1ac5536 in /usr/local/lib/python3.6/dist-packages/torch/lib/libc10.so)\nframe #1: <unknown function> + 0x1cf1e (0x7f65a1d0ef1e in /usr/local/lib/python3.6/dist-packages/torch/lib/libc10_cuda.so)\nframe #2: <unknown function> + 0x1df9e (0x7f65a1d0ff9e in /usr/local/lib/python3.6/dist-packages/torch/lib/libc10_cuda.so)\nframe #3: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x135 (0x7f65a48bbfd5 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cuda.so)\nframe #4: <unknown function> + 0xf9310b (0x7f65a2eb410b in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cuda.so)\nframe #5: <unknown function> + 0xfdc9f7 (0x7f65a2efd9f7 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cuda.so)\nframe #6: <unknown function> + 0x1075389 (0x7f65da848389 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #7: <unknown function> + 0x10756c7 (0x7f65da8486c7 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #8: <unknown function> + 0xe3c42e (0x7f65da60f42e in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #9: at::TensorIterator::allocate_outputs() + 0x38c (0x7f65da60f94c in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #10: at::TensorIterator::build() + 0x208 (0x7f65da610d28 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #11: at::TensorIterator::binary_op(at::Tensor&, at::Tensor const&, at::Tensor const&, bool) + 0x146 (0x7f65da611216 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #12: at::native::mul(at::Tensor const&, at::Tensor const&) + 0x3a (0x7f65da330eba in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #13: at::native::mul(at::Tensor const&, c10::Scalar) + 0x3d (0x7f65da33827d in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #14: <unknown function> + 0x1159002 (0x7f65da92c002 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #15: <unknown function> + 0x10c5b92 (0x7f65da898b92 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #16: <unknown function> + 0x2d4ac9b (0x7f65dc51dc9b in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #17: <unknown function> + 0x10c5b92 (0x7f65da898b92 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #18: at::Tensor::mul(c10::Scalar) const + 0x133 (0x7f65e8f077f3 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_python.so)\nframe #19: torch::autograd::generated::ErfBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x18a (0x7f65dc08299a in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #20: <unknown function> + 0x2d89c05 (0x7f65dc55cc05 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #21: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&) + 0x16f3 (0x7f65dc559f03 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #22: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&, bool) + 0x3d2 (0x7f65dc55ace2 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #23: torch::autograd::Engine::thread_init(int) + 0x39 (0x7f65dc553359 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #24: torch::autograd::python::PythonEngine::thread_init(int) + 0x38 (0x7f65e8c92378 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_python.so)\nframe #25: <unknown function> + 0xbd6df (0x7f660d09e6df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)\nframe #26: <unknown function> + 0x76db (0x7f660e1806db in /lib/x86_64-linux-gnu/libpthread.so.0)\nframe #27: clone + 0x3f (0x7f660e4b988f in /lib/x86_64-linux-gnu/libc.so.6)\n"]}]},{"cell_type":"code","metadata":{"_uuid":"fa1b1b6080cae3b837cc93959278b7ad936bb8dc","id":"IdMnEFuc8FYy","colab_type":"code","colab":{}},"source":["model.eval()\n","predictions = []\n","true_labels = []\n","eval_loss, eval_accuracy = 0, 0\n","nb_eval_steps, nb_eval_examples = 0, 0\n","for batch in DL_valid:\n","    batch = tuple(t.to(device) for t in batch)\n","    b_input_ids, b_input_mask, b_labels = batch\n","\n","    with torch.no_grad():\n","        tmp_eval_loss = model(b_input_ids, token_type_ids=None,\n","                              attention_mask=b_input_mask, labels=b_labels)\n","        logits = model(b_input_ids, token_type_ids=None,\n","                       attention_mask=b_input_mask)\n","        \n","    logits = logits.detach().cpu().numpy()\n","    predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n","    label_ids = b_labels.to('cpu').numpy()\n","    true_labels.append(label_ids)\n","    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n","\n","    eval_loss += tmp_eval_loss.mean().item()\n","    eval_accuracy += tmp_eval_accuracy\n","\n","    nb_eval_examples += b_input_ids.size(0)\n","    nb_eval_steps += 1\n","\n","pred_tags = [[tags2vals[p_i] for p_i in p] for p in predictions]\n","valid_tags = [[tags2vals[l_ii] for l_ii in l_i] for l in true_labels for l_i in l ]\n","print(\"Validation loss: {}\".format(eval_loss/nb_eval_steps))\n","print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n","print(\"Validation F1-Score: {}\".format(f1_score(pred_tags, valid_tags)))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"_uuid":"4dc41595141dfe7c7cabf671ca0dc1eca444d77d","id":"bJ_vNPBp8FY-","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}