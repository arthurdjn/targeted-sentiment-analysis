{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Targeted Sentiment Analysis**\n",
    "\n",
    "This document introduces one of the tasks for the Spring 2020 Home Exam for\n",
    "IN5550: Targeted Sentiment Analysis for Norwegian. For general instructions\n",
    "regarding the home exam, see the information at the semester page for the\n",
    "course:\n",
    "\n",
    "https://www.uio.no/studier/emner/matnat/ifi/IN5550/v20/exam.html\n",
    "\n",
    "\n",
    "## The task in short\n",
    "\n",
    "Fine-grained *Sentiment Analysis* (SA), sometimes referred to as *Opinion Analysis/Mining*, \n",
    "is the task of identifying opinions in text and analyzing them in terms of their polar expressions, targets, and holders. \n",
    "In this task we will focus on targeted SA, i.e. the identification of the target of opinion along with the\n",
    "polarity with which it is associated in the text (positive/negative). \n",
    "\n",
    "In the example below, for instance, the target of the opinion is disken *the disk* and it\n",
    "is ascribed a positive polarity by the surrounding context.\n",
    "\n",
    "*Denne diskenP OS er svært stillegående*\n",
    "\n",
    "*This disk is very quiet-going*\n",
    "\n",
    "**This disk runs very quietly**\n",
    "\n",
    "All data and pre-code needed to work on this assignment is available from:\n",
    "\n",
    "https://github.uio.no/in5550/2020/tree/master/exam/targeted_sa\n",
    "\n",
    "\n",
    "## Data\n",
    "\n",
    "We will be working with the recently released NoReCfine, a dataset for finegrained sentiment analysis in Norwegian. \n",
    "The texts in the dataset have been annotated with respect to polar expressions, targets and holders of opinion but\n",
    "we will here be focusing on identification of targets and their polarity only.\n",
    "The underlying texts are taken from a corpus of professionally authored reviews\n",
    "from multiple news-sources and across a wide variety of domains, including\n",
    "literature, games, music, products, movies and more. Table 1 presents the\n",
    "dataset and its annotated targets. The dataset is distributed with pre-defined\n",
    "train, development and test splits.\n",
    "\n",
    "\n",
    "|            | Train | Dev  | Test | Total | Avg length |\n",
    "|------------|-------|------|------|-------|------------|\n",
    "| **Sentiments** | 6145  | 1184 | 930  | 8259  | 16.8       |\n",
    "| **Targets**    | 4458  | 832  | 702  | 5999  | 2.0        |\n",
    "\n",
    "\n",
    "## Data format\n",
    "The task respository contains data that has been converted from the native\n",
    "json-format of NoReCfineto the conll-format assumed for this task: each line is\n",
    "a token and label, separated by a tab, and sentences are separated by a new\n",
    "line. The labels are BIO + polarity (Positive, Negative) for a total of 5 labels\n",
    "(B-targ-Positive, I-targ-Positive, B-targ-Negative, I-targ-Negative, O).\n",
    "\n",
    "\n",
    "| sent_id            | 501595-13-04    |\n",
    "|--------------------|-----------------|\n",
    "| Munken             | B-targ-Positive |\n",
    "| Bistro             | I-targ-Positive |\n",
    "| er                 | O               |\n",
    "| en                 | O               |\n",
    "| hyggelig           | O               |\n",
    "| nabolagsrestaurant | O               |\n",
    "| for                | O               |\n",
    "| hverdagslige       | O               |\n",
    "| og                 | O               |\n",
    "| uformelle          | O               |\n",
    "| anledninger        | O               |\n",
    "| .                  | O               |\n",
    "\n",
    "\n",
    "## Modeling\n",
    "The main objective of the home exam is to train a neural system to perform\n",
    "targeted sentiment analysis for Norwegian text. In order to complete the task\n",
    "you should follow these steps:\n",
    "\n",
    "### Baseline model\n",
    "You can base your work on PyTorch pre-code for a baseline\n",
    "model and evaluate this on the development and test data. This is a simple\n",
    "bi-LSTM model that leaves room for a number of possible improvements.\n",
    "\n",
    "### Experimental evaluation\n",
    "You should experimentally evaluate the effect of at\n",
    "least three different changes to your basic system. Some possible directions\n",
    "for further experimentation are provided below, but you are also free to\n",
    "come up with experimental directions of your own. Evaluation of changes\n",
    "to your systems should be performed on the development set.\n",
    "\n",
    "### Held-out testing \n",
    "The best configuration of your system following experimentation should be evaluated on the test set.\n",
    "\n",
    "\n",
    "## Write a report\n",
    "Your experiments should be described in a report following\n",
    "the exam template detailing your experiments and findings.\n",
    "\n",
    "## Evaluation\n",
    "The models will be evaluated on two different metrics: proportional F1and\n",
    "binary F1. Binary Overlap counts any overlapping predicted and gold span as\n",
    "correct. Proportional Overlap instead assigns precision as the ratio of overlap\n",
    "with the predicted span and recall as the ratio of overlap with the gold span,\n",
    "which reduces to token-level F1. Proportional F1is therefore a stricter measure\n",
    "than Binary F1. You will have scripts available to calculate these scores.\n",
    "\n",
    "## Possible directions for experimentation\n",
    "You can explore a number of directions we suggest below, but you’re encouraged\n",
    "to come up with other ideas for yourself.\n",
    "\n",
    "* Experiment with alternative label encoding (e.g. BIOUL)\n",
    "* Compare pipeline vs. joint prediction approaches.\n",
    "* Impact of different architectures:\n",
    "    * LSTM vs. GRU vs. Transformer\n",
    "    * Include character-level information\n",
    "    * Depth of model (2-layer, 3-layer, etc)\n",
    "* Effect of using pretrained models (ELMo1, BERT2, or Multilingual Bert3)\n",
    "* Perform a small error analysis (confusion matrix, the most common errors).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **0. Set Up**\n",
    "\n",
    "Before diving in the models, let's reload the notebook to keep it updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# This is a bit of magic to make matplotlib figures appear inline in the notebook\n",
    "# rather than in a new window.\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, let's load the dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, PackedSequence\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Data science\n",
    "import spacy\n",
    "import numpy as np\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's not forget to fix the seed for random generated numbers !\n",
    "SEED = 2020 \n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. Baseline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SenTarget package\n",
    "from baseline.dataset import Vocab, ConllDataset\n",
    "from baseline.word2vec import Word2Vec\n",
    "from baseline.utils import binary_analysis, proportional_analysis, get_analysis\n",
    "from baseline.model import BiLSTM\n",
    "\n",
    "# Progress Bar\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_LAYERS = 1\n",
    "HIDDEN_DIM = 100\n",
    "BATCH_SIZE = 50\n",
    "DROPOUT = 0.01\n",
    "EMBEDDING_DIM = 100\n",
    "EMBEDDINGS = \".vector_cache/model.txt\" # Change to the path where you downloaded the `58.zip` vector file.\n",
    "TRAIN_EMBEDDINGS = True\n",
    "LEARNING_RATE = 0.01\n",
    "EPOCHS = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get embeddings (CHANGE TO GLOVE OR FASTTEXT EMBEDDINGS)\n",
    "embeddings = Word2Vec(EMBEDDINGS)\n",
    "w2idx = embeddings._w2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1182371, 100)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings._matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create shared vocabulary for tasks\n",
    "vocab = Vocab(train=True)\n",
    "\n",
    "# Update with word2idx from pretrained embeddings so we don't lose them\n",
    "# making sure to change them by two to avoid overwriting the PAD and UNK\n",
    "# tokens at index 0 and 1\n",
    "with_unk = {}\n",
    "for word, idx in embeddings._w2idx.items():\n",
    "    with_unk[word] = idx + 2\n",
    "    \n",
    "vocab.update(with_unk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import datasets\n",
    "# This will update vocab with words not found in embeddings\n",
    "dataset = ConllDataset(vocab)\n",
    "\n",
    "train_iter = dataset.get_split(\"data/train.conll\")\n",
    "dev_iter = dataset.get_split(\"data/dev.conll\")\n",
    "test_iter = dataset.get_split(\"data/test.conll\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raws, words, targets, idxs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['Texas-baserte',\n",
       "  'Retro',\n",
       "  'Studios',\n",
       "  'videreførte',\n",
       "  'tradisjonen',\n",
       "  'med',\n",
       "  'å',\n",
       "  'utvikle',\n",
       "  'spillserien',\n",
       "  'utenfor',\n",
       "  'Nintendos',\n",
       "  'egne',\n",
       "  'studioer',\n",
       "  'med',\n",
       "  'Donkey',\n",
       "  'Kong',\n",
       "  'Country',\n",
       "  'Return',\n",
       "  'på',\n",
       "  'Wii-konsollen',\n",
       "  'i',\n",
       "  '2010',\n",
       "  '.'],\n",
       " tensor([1192028, 1192029, 1183207, 1192030,    6342,      16, 1182398,    2220,\n",
       "           78093,     492, 1188063,     808,   42162,      16, 1192021, 1187209,\n",
       "         1192022, 1192031, 1182380, 1192032,       5,     623,       3]),\n",
       " tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"raws, words, targets, idxs\")\n",
    "test_iter[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Embeddings update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new embedding matrix which includes the pretrained embeddings\n",
    "# as well as new embeddings for PAD UNK and tokens not found in the\n",
    "# pretrained embeddings.\n",
    "diff = len(vocab) - embeddings.vocab_length - 2\n",
    "PAD_UNK_embeddings = np.zeros((2, EMBEDDING_DIM))\n",
    "new_embeddings = np.zeros((diff, EMBEDDING_DIM))\n",
    "new_matrix = np.concatenate((PAD_UNK_embeddings,\n",
    "                             embeddings._matrix,\n",
    "                             new_embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the data iterators for the LSTM model. The batch size for the dev\n",
    "# and test loader is set to 1 for the predict() and evaluate() methods\n",
    "train_loader = DataLoader(train_iter,\n",
    "                          batch_size = BATCH_SIZE,\n",
    "                          collate_fn = train_iter.collate_fn,\n",
    "                          shuffle = True)\n",
    "\n",
    "dev_loader = DataLoader(dev_iter,\n",
    "                        batch_size = 1,\n",
    "                        collate_fn = dev_iter.collate_fn,\n",
    "                        shuffle = False)\n",
    "\n",
    "test_loader = DataLoader(test_iter,\n",
    "                         batch_size = 1,\n",
    "                         collate_fn = test_iter.collate_fn,\n",
    "                         shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically determine whether to run on CPU or GPU\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6. Model instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BiLSTM(word2idx = vocab,\n",
    "               embedding_matrix = new_matrix,\n",
    "               embedding_dim = EMBEDDING_DIM,\n",
    "               hidden_dim = HIDDEN_DIM,\n",
    "               device = device,\n",
    "               output_dim = 5,\n",
    "               num_layers = NUM_LAYERS,\n",
    "               word_dropout = DROPOUT,\n",
    "               learning_rate = LEARNING_RATE,\n",
    "               train_embeddings = TRAIN_EMBEDDINGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/119 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "model.fit(train_loader, dev_loader, epochs = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.8. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_f1, propor_f1 = model.evaluate(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For printing the predictions, we would prefer to see the actual labels,\n",
    "# rather than the indices, so we create and index to label dictionary\n",
    "# which the print_predictions method takes as input.\n",
    "\n",
    "idx2label = {i: l for l, i in dataset.label2idx.items()}\n",
    "\n",
    "model.print_predictions(test_loader,\n",
    "                        outfile = \"predictions.conll\",\n",
    "                        idx2label = idx2label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
